# -*- coding: utf-8 -*-
"""Desafio Breno Teodomiro - Cálculo de Métricas de Avaliação de Aprendizado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EwCcI8BfkEZAFQBqMzrtDQ3_9EJWqr_u

Descrição do Desafio
Cálculo de Métricas de Avaliação de Aprendizado

Neste projeto, vamos calcular as principais métricas para avaliação de modelos de classificação de dados, como acurácia, sensibilidade (recall), especificidade, precisão e F-score. Para que seja possível implementar estas funções, você deve utilizar os métodos e suas fórmulas correspondentes (Tabela 1).

Para a leitura dos valores de VP, VN, FP e FN, será necessário escolher uma matriz de confusão para a base dos cálculos. Essa matriz você pode escolher de forma arbitraria, pois nosso objetivo é entender como funciona cada métrica.  



Tabela 1: Visão geral das métricas usadas para avaliar métodos de classificação. VP: verdadeiros positivos; FN: falsos negativos; FP: falsos positivos; VN: verdadeiros negativos; P: precisão; S: sensibilidade; N: total de elementos.

---

DESCRIÇÃO
Neste projeto, vamos calcular as principais métricas para avaliação de modelos de classificação de dados, como acurácia, sensibilidade (recall), especificidade, precisão e F-score.

---
"""

# Exemplo de valores da matriz de confusão:
# VP (Verdadeiros Positivos) = 50
# FN (Falsos Negativos)    = 10
# FP (Falsos Positivos)    = 5
# VN (Verdadeiros Negativos)= 35

# Valores da matriz de confusão
VP = 50  # Verdadeiros Positivos
FN = 10  # Falsos Negativos
FP = 5   # Falsos Positivos
VN = 35  # Verdadeiros Negativos

# Cálculo do total de elementos
N = VP + FN + FP + VN

# Cálculo das métricas:
# Acurácia: proporção de previsões corretas
acuracia = (VP + VN) / N

# Sensibilidade (Recall): capacidade de identificar corretamente os positivos
sensibilidade = VP / (VP + FN)

# Especificidade: capacidade de identificar corretamente os negativos
especificidade = VN / (VN + FP)

# Precisão: proporção de previsões positivas corretas
precisao = VP / (VP + FP)

# F-score (F1 Score): média harmônica entre precisão e sensibilidade
f_score = 2 * (precisao * sensibilidade) / (precisao + sensibilidade)

# Impressão dos resultados com duas casas decimais
print("Acurácia: {:.2f}".format(acuracia))
print("Sensibilidade (Recall): {:.2f}".format(sensibilidade))
print("Especificidade: {:.2f}".format(especificidade))
print("Precisão: {:.2f}".format(precisao))
print("F-score: {:.2f}".format(f_score))